RDF-data-mining
=========================================================
Code for paper [*Learning from biomedical linked data to suggest valid pharmacogenes*](https://doi.org/10.1186/s13326-017-0125-1).

Contents
--------

The project contains three modules :

* Data Sources :
  * load.sh : a script to load a file or a directory (turtle, rdf or nq) into blazegraph: : `./load.sh path_to_file_or_directory`
  * raw data used in Dalleau, Marzougui et al. are available at http://pgxlod.loria.fr, Write to coulet at loria dot fr for requesting an access.

* Pre-processing :
  * `preprocessing.py` : a script to generate training and test sets from the inputs. Outputs are : training_pairs.tsv, test_pairs.tsv. ATTENTION : Currently the script overwrites the existing training pairs with new randomly generated negative examples, So you need to backup existing tsv files before running the script.
  * `getSubgraphs.py` : This scripts extracts a subgraph from main_triplestore defined by predicates in to_include or to_exclude, and joins the training pairs into one node. To obtain the whole graph you can set to_exclude = []. Outputs, which serve as input to mustard, are :
    * (un)directed_subgraph : list of rdf files generated by the script. Each file correspond to a set of triples with a specific predicate. Mappings between file numbers and predicates are in (un)directed_subgraph.log.
    * directed_fullgraph.rdf : this file contains the neighberhoods of the instances (up to the maximum depth = 18), extracted using GAS implementation of Blazegraph (see Blazegraph wiki). This is because mustard can not load the whole triplestore into memory and extract the instances neighberhoods, therefore we exctract them manually.

* Processing :
A java project using mustard to run experiments. Netbeans project. Add jars in the dependencies folder to the project before build. Outputs  are in results folder.

* Wokflow :
  * run `preprocessing.py` to generate a new training set.
  * run *blazegraph* from main_triplestore.
  * run `getsubgraphs.py` to generate subgraphs.
  * run the code in *processing* to train and generate results.

**Useful links**

* [https://www.w3.org/2009/Talks/0615-qbe/](https://www.w3.org/2009/Talks/0615-qbe/)<br>
* [http://be.amazd.com/link-prediction/](http://be.amazd.com/link-prediction/)<br>
* [wifo5-03.informatik.uni-mannheim.de/bizer/berlinsparqlbenchmark/results/V7/](wifo5-03.informatik.uni-mannheim.de/bizer/berlinsparqlbenchmark/results/V7/)<br>
* [http://www.snee.com/bobdc.blog/2009/09/appreciating-sparql-construct.html](http://www.snee.com/bobdc.blog/2009/09/appreciating-sparql-construct.html)<br>
* [http://www.slideshare.net/fabien_gandon/sparql-in-a-nutshell](http://www.slideshare.net/fabien_gandon/sparql-in-a-nutshell)




